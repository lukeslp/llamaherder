// Auto-generated by models.py
const modelData = {
  "categories": [
    {
      "label": "Dreamwalker Models",
      "models": [
        {
          "value": "camina:latest",
          "text": "camina",
          "data-size": "8.4GB",
          "data-info": "Parameters: 14.7B | Architecture: Phi3 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16",
          "selected": true
        },
        {
          "value": "drummer-arxiv:latest",
          "text": "drummer-arxiv",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-code:latest",
          "text": "drummer-code",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-dataproc:latest",
          "text": "drummer-dataproc",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-document:latest",
          "text": "drummer-document",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-18"
        },
        {
          "value": "drummer-finance:latest",
          "text": "drummer-finance",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-infinite:latest",
          "text": "drummer-infinite",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-knowledge:latest",
          "text": "drummer-knowledge",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-scrape:3b",
          "text": "drummer-scrape:3b",
          "data-size": "1.9GB",
          "data-info": "Parameters: 3.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "drummer-scrape:latest",
          "text": "drummer-scrape",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-timecalc:latest",
          "text": "drummer-timecalc",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "drummer-wayback:latest",
          "text": "drummer-wayback",
          "data-size": "1.9GB",
          "data-info": "Parameters: 3.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-17"
        }
      ]
    },
    {
      "label": "Code Models",
      "models": [
        {
          "value": "StarCoder2:latest",
          "text": "StarCoder2",
          "data-size": "1.6GB",
          "data-info": "Parameters: 3B | Architecture: Starcoder2 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        },
        {
          "value": "codellama:7b",
          "text": "codellama:7b",
          "data-size": "3.6GB",
          "data-info": "Parameters: 7B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        },
        {
          "value": "opencoder:8b",
          "text": "opencoder:8b",
          "data-size": "4.4GB",
          "data-info": "Parameters: 7.8B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "qwen2.5-coder:7b",
          "text": "qwen2.5-coder:7b",
          "data-size": "4.4GB",
          "data-info": "Parameters: 7.6B | Architecture: Qwen2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        }
      ]
    },
    {
      "label": "Experimental Models",
      "models": [
        {
          "value": "coolhand/impossible_alt:13b",
          "text": "impossible_alt:13b",
          "data-size": "7.5GB",
          "data-info": "Parameters: 13.0B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-21"
        },
        {
          "value": "falcon3:10b",
          "text": "falcon3:10b",
          "data-size": "5.9GB",
          "data-info": "Parameters: 10.3B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "gemma2:latest",
          "text": "gemma2",
          "data-size": "5.1GB",
          "data-info": "Parameters: 9.2B | Architecture: Gemma2 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        }
      ]
    },
    {
      "label": "Foundation Models",
      "models": [
        {
          "value": "deepseek-r1:1.5b",
          "text": "deepseek-r1:1.5b",
          "data-size": "1.0GB",
          "data-info": "Parameters: 1.8B | Architecture: Qwen2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-24"
        },
        {
          "value": "deepseek-r1:14b",
          "text": "deepseek-r1:14b",
          "data-size": "8.4GB",
          "data-info": "Parameters: 14.8B | Architecture: Qwen2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-24"
        },
        {
          "value": "deepseek-r1:7b",
          "text": "deepseek-r1:7b",
          "data-size": "4.4GB",
          "data-info": "Parameters: 7.6B | Architecture: Qwen2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-24"
        },
        {
          "value": "deepseek-r1:8b",
          "text": "deepseek-r1:8b",
          "data-size": "4.6GB",
          "data-info": "Parameters: 8.0B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-24"
        },
        {
          "value": "granite3-dense:latest",
          "text": "granite3-dense",
          "data-size": "1.5GB",
          "data-info": "Parameters: 2.6B | Architecture: Granite | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-17"
        },
        {
          "value": "granite3.1-dense:8b",
          "text": "granite3.1-dense:8b",
          "data-size": "4.6GB",
          "data-info": "Parameters: 8.2B | Architecture: Granite | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "granite3.1-moe:latest",
          "text": "granite3.1-moe",
          "data-size": "1.9GB",
          "data-info": "Parameters: 3.3B | Architecture: Granitemoe | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "olmo2:13b",
          "text": "olmo2:13b",
          "data-size": "7.8GB",
          "data-info": "Parameters: 13.7B | Architecture: Olmo2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "olmo2:7b",
          "text": "olmo2:7b",
          "data-size": "4.2GB",
          "data-info": "Parameters: 7.3B | Architecture: Olmo2 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        }
      ]
    },
    {
      "label": "Llama Models",
      "models": [
        {
          "value": "llama2-uncensored:7b",
          "text": "llama2-uncensored:7b",
          "data-size": "3.6GB",
          "data-info": "Parameters: 7B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2024-12-18"
        },
        {
          "value": "llama3.1:8b",
          "text": "llama3.1:8b",
          "data-size": "4.6GB",
          "data-info": "Parameters: 8.0B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-17"
        },
        {
          "value": "llama3.2:1b",
          "text": "llama3.2:1b",
          "data-size": "1.2GB",
          "data-info": "Parameters: 1.2B | Architecture: Llama | Format: GGUF | Quantization: Q8_0 | Updated: 2025-01-16"
        },
        {
          "value": "llama3.2:3b",
          "text": "llama3.2:3b",
          "data-size": "1.9GB",
          "data-info": "Parameters: 3.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2024-12-18"
        }
      ]
    },
    {
      "label": "Mistral Models",
      "models": [
        {
          "value": "mistral:7b",
          "text": "mistral:7b",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        },
        {
          "value": "mistral:latest",
          "text": "mistral",
          "data-size": "3.8GB",
          "data-info": "Parameters: 7.2B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-15"
        }
      ]
    },
    {
      "label": "Small & Fast Models",
      "models": [
        {
          "value": "dolphin3:latest",
          "text": "dolphin3",
          "data-size": "4.6GB",
          "data-info": "Parameters: 8.0B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "nemotron-mini:latest",
          "text": "nemotron-mini",
          "data-size": "2.5GB",
          "data-info": "Parameters: 4.2B | Architecture: Nemotron | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-17"
        },
        {
          "value": "phi3.5:latest",
          "text": "phi3.5",
          "data-size": "2.0GB",
          "data-info": "Parameters: 3.8B | Architecture: Phi3 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        },
        {
          "value": "phi3:latest",
          "text": "phi3",
          "data-size": "2.0GB",
          "data-info": "Parameters: 3.8B | Architecture: Phi3 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-17"
        },
        {
          "value": "phi4:latest",
          "text": "phi4",
          "data-size": "8.4GB",
          "data-info": "Parameters: 14.7B | Architecture: Phi3 | Format: GGUF | Quantization: Q4_K_M | Updated: 2025-01-16"
        },
        {
          "value": "smollm2:135m",
          "text": "smollm2:135m",
          "data-size": "258MB",
          "data-info": "Parameters: 134.52M | Architecture: Llama | Format: GGUF | Quantization: F16 | Updated: 2025-01-16"
        },
        {
          "value": "smollm2:360m",
          "text": "smollm2:360m",
          "data-size": "692MB",
          "data-info": "Parameters: 361.82M | Architecture: Llama | Format: GGUF | Quantization: F16 | Updated: 2025-01-16"
        },
        {
          "value": "smollm:1.7b",
          "text": "smollm:1.7b",
          "data-size": "945MB",
          "data-info": "Parameters: 1.7B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        }
      ]
    },
    {
      "label": "Vision Models",
      "models": [
        {
          "value": "bakllava:latest",
          "text": "bakllava",
          "data-size": "4.4GB",
          "data-info": "Parameters: 7B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-21"
        },
        {
          "value": "llama3.2-vision:11b",
          "text": "llama3.2-vision:11b",
          "data-size": "7.4GB",
          "data-info": "Parameters: 9.8B | Architecture: Mllama | Format: GGUF | Quantization: Q4_K_M | Updated: 2024-12-18"
        },
        {
          "value": "llava-llama3:latest",
          "text": "llava-llama3",
          "data-size": "5.2GB",
          "data-info": "Parameters: 8B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2024-12-18"
        },
        {
          "value": "llava-phi3:latest",
          "text": "llava-phi3",
          "data-size": "2.7GB",
          "data-info": "Parameters: 4B | Architecture: Llama | Format: GGUF | Quantization: Q4_K_M | Updated: 2024-12-18"
        },
        {
          "value": "llava:13b",
          "text": "llava:13b",
          "data-size": "7.5GB",
          "data-info": "Parameters: 13B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-21"
        },
        {
          "value": "llava:7b",
          "text": "llava:7b",
          "data-size": "4.4GB",
          "data-info": "Parameters: 7B | Architecture: Llama | Format: GGUF | Quantization: Q4_0 | Updated: 2024-12-20"
        },
        {
          "value": "minicpm-v:latest",
          "text": "minicpm-v",
          "data-size": "5.1GB",
          "data-info": "Parameters: 7.6B | Architecture: Qwen2 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        },
        {
          "value": "moondream:latest",
          "text": "moondream",
          "data-size": "1.6GB",
          "data-info": "Parameters: 1B | Architecture: Phi2 | Format: GGUF | Quantization: Q4_0 | Updated: 2025-01-16"
        }
      ]
    }
  ]
};
